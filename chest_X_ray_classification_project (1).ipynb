{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fP_WM8eXkVKN"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ABIZjJkRhwqF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D, Flatten, BatchNormalization, Dropout, Concatenate\n",
    "from tensorflow.keras.applications import MobileNetV2, DenseNet169\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2GNW576k2hu"
   },
   "source": [
    "# Load Pre- Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzwQNoh0kyaT",
    "outputId": "f076cc09-5a16-47f2-cf04-7b44cd467106"
   },
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "mobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "densenet_base = DenseNet169(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrApz4wklQKm"
   },
   "source": [
    "# Freeze Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WIstFOWek9TB"
   },
   "outputs": [],
   "source": [
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in densenet_base.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKeFuEUolY-N"
   },
   "source": [
    "# Building Stacked Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1Y1MTDm1lVVN"
   },
   "outputs": [],
   "source": [
    "input_layer = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "DcPfwGU4ljPs"
   },
   "outputs": [],
   "source": [
    "# Process MobileNetV2 output\n",
    "mobilenet_output = GlobalAveragePooling2D()(mobilenet_base(input_layer))\n",
    "mobilenet_output = Flatten()(mobilenet_output)\n",
    "\n",
    "# Process DenseNet169 output\n",
    "densenet_output = GlobalAveragePooling2D()(densenet_base(input_layer))\n",
    "densenet_output = Flatten()(densenet_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "it8_4d6llrDM"
   },
   "outputs": [],
   "source": [
    "# Merge outputs\n",
    "merged = Concatenate()([mobilenet_output, densenet_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "iOSN5OQKlufK"
   },
   "outputs": [],
   "source": [
    "# Adding Additional Layers\n",
    "x = BatchNormalization()(merged)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kkmfodATlyz8"
   },
   "outputs": [],
   "source": [
    "# Final output layer with 2 classes\n",
    "output_layer = Dense(2, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "dKCKmqvEl5KH"
   },
   "outputs": [],
   "source": [
    "stacked_model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JvNecIJTl7Ac"
   },
   "outputs": [],
   "source": [
    "stacked_model.compile(optimizer=Adam(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoOXOgEymKHS"
   },
   "source": [
    "# Image Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "71cLywDKl_K4"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=40,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.2,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "_HatSGlXmo9C"
   },
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NsvuDtzHnoKf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\MANISH JAISWAL\\AppData\\Local\\Temp\\ipykernel_10128\\1953560405.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  'D:\\\\Anime\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\train',\n",
      "C:\\Users\\MANISH JAISWAL\\AppData\\Local\\Temp\\ipykernel_10128\\1953560405.py:8: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  'D:\\\\Anime\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\val',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:\\\\Anime\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'D:\\\\Anime\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdzWHCIRnsAo"
   },
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "r0Y9g_Lunu7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8462 - loss: 0.3941"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 3s/step - accuracy: 0.8465 - loss: 0.3934 - val_accuracy: 0.8750 - val_loss: 0.2567\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.8750 - val_loss: 0.2567\n",
      "Epoch 3/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 3s/step - accuracy: 0.9330 - loss: 0.1766 - val_accuracy: 0.9375 - val_loss: 0.1331\n",
      "Epoch 4/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9375 - val_loss: 0.1331\n",
      "Epoch 5/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m517s\u001b[0m 3s/step - accuracy: 0.9436 - loss: 0.1433 - val_accuracy: 0.7500 - val_loss: 0.5252\n",
      "Epoch 6/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.7500 - val_loss: 0.5252\n",
      "Epoch 7/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m581s\u001b[0m 4s/step - accuracy: 0.9403 - loss: 0.1440 - val_accuracy: 0.9375 - val_loss: 0.1793\n",
      "Epoch 8/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9375 - val_loss: 0.1793\n",
      "Epoch 9/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m585s\u001b[0m 4s/step - accuracy: 0.9510 - loss: 0.1314 - val_accuracy: 1.0000 - val_loss: 0.0977\n",
      "Epoch 10/10\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0977\n"
     ]
    }
   ],
   "source": [
    "history = stacked_model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0977\n",
      "Validation Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = stacked_model.evaluate(val_generator)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model.save('model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10s/step\n",
      "Predicted class: Pneumonia\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "class_names = ['Normal', 'Pneumonia']\n",
    "\n",
    "img_path = 'D:\\\\Anime\\\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\test\\\\PNEUMONIA\\\\person26_virus_60.jpeg'  \n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "predictions = stacked_model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "print(f'Predicted class: {class_names[predicted_class]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_path = '\"D:\\Anime\\DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\[TutsNode.org] - DeepLearningComplete Computer Vision With GenAI-12 Projects\\\\8. Datasets Part 1 (Till this Point)\\\\test\\\\NORMAL\\\\IM-0022-0001.jpeg'  \n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0\n",
    "\n",
    "predictions = stacked_model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "print(f'Predicted class: {class_names[predicted_class]}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
